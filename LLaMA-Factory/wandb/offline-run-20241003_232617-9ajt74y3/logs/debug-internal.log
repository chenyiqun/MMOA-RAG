2024-10-03 23:26:17,781 INFO    StreamThr :23866 [internal.py:wandb_internal():86] W&B internal server running at pid: 23866, started at: 2024-10-03 23:26:17.780462
2024-10-03 23:26:17,782 DEBUG   HandlerThread:23866 [handler.py:handle_request():146] handle_request: status
2024-10-03 23:26:17,787 INFO    WriterThread:23866 [datastore.py:open_for_write():87] open: /root/paddlejob/workspace/env_run/llama3/LLaMA-Factory-main/wandb/offline-run-20241003_232617-9ajt74y3/run-9ajt74y3.wandb
2024-10-03 23:26:17,793 DEBUG   HandlerThread:23866 [handler.py:handle_request():146] handle_request: run_start
2024-10-03 23:26:17,804 DEBUG   HandlerThread:23866 [system_info.py:__init__():27] System info init
2024-10-03 23:26:17,804 DEBUG   HandlerThread:23866 [system_info.py:__init__():42] System info init done
2024-10-03 23:26:17,804 INFO    HandlerThread:23866 [system_monitor.py:start():194] Starting system monitor
2024-10-03 23:26:17,805 INFO    SystemMonitor:23866 [system_monitor.py:_start():158] Starting system asset monitoring threads
2024-10-03 23:26:17,805 INFO    HandlerThread:23866 [system_monitor.py:probe():214] Collecting system info
2024-10-03 23:26:17,805 INFO    SystemMonitor:23866 [interfaces.py:start():190] Started cpu monitoring
2024-10-03 23:26:17,806 INFO    SystemMonitor:23866 [interfaces.py:start():190] Started disk monitoring
2024-10-03 23:26:17,807 INFO    SystemMonitor:23866 [interfaces.py:start():190] Started gpu monitoring
2024-10-03 23:26:17,807 INFO    SystemMonitor:23866 [interfaces.py:start():190] Started memory monitoring
2024-10-03 23:26:17,808 INFO    SystemMonitor:23866 [interfaces.py:start():190] Started network monitoring
2024-10-03 23:26:17,856 DEBUG   HandlerThread:23866 [system_info.py:probe():151] Probing system
2024-10-03 23:26:17,861 DEBUG   HandlerThread:23866 [gitlib.py:_init_repo():56] git repository is invalid
2024-10-03 23:26:17,861 DEBUG   HandlerThread:23866 [system_info.py:probe():199] Probing system done
2024-10-03 23:26:17,862 DEBUG   HandlerThread:23866 [system_monitor.py:probe():223] {'os': 'Linux-5.10.0-1.0.0.28-x86_64-with-glibc2.29', 'python': '3.8.10', 'heartbeatAt': '2024-10-03T15:26:17.856188', 'startedAt': '2024-10-03T15:26:17.773913', 'docker': None, 'cuda': None, 'args': ('examples/train_lora/llama3_lora_reward.yaml',), 'state': 'running', 'program': '/root/paddlejob/workspace/env_run/llama3/LLaMA-Factory-main/src/llamafactory/launcher.py', 'codePathLocal': 'src/llamafactory/launcher.py', 'codePath': 'src/llamafactory/launcher.py', 'host': 'yq01-sys-hic-k8s-v100-box-a225-0209.yq01.baidu.com', 'username': 'root', 'executable': '/usr/bin/python3.8', 'cpu_count': 40, 'cpu_count_logical': 40, 'cpu_freq': {'current': 2400.0081, 'min': 1000.0, 'max': 2400.0}, 'cpu_freq_per_core': [{'current': 2400.0, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.004, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.001, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.004, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.001, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.0, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.018, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.01, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.019, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.032, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.02, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.007, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.004, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.0, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.009, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.008, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.0, 'min': 1000.0, 'max': 2400.0}, {'current': 2399.999, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.009, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.008, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.001, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.0, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.0, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.002, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.006, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.014, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.025, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.0, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.007, 'min': 1000.0, 'max': 2400.0}, {'current': 2399.999, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.013, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.01, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.013, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.014, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.016, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.018, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.004, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.002, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.018, 'min': 1000.0, 'max': 2400.0}, {'current': 2400.009, 'min': 1000.0, 'max': 2400.0}], 'disk': {'/': {'total': 3607.857608795166, 'used': 800.8740043640137}}, 'gpu': 'Tesla V100-SXM2-32GB', 'gpu_count': 8, 'gpu_devices': [{'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34359738368}, {'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34359738368}, {'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34359738368}, {'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34359738368}, {'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34359738368}, {'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34359738368}, {'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34359738368}, {'name': 'Tesla V100-SXM2-32GB', 'memory_total': 34359738368}], 'memory': {'total': 502.2030906677246}}
2024-10-03 23:26:17,862 INFO    HandlerThread:23866 [system_monitor.py:probe():224] Finished collecting system info
2024-10-03 23:26:17,862 INFO    HandlerThread:23866 [system_monitor.py:probe():227] Publishing system info
2024-10-03 23:26:17,863 INFO    HandlerThread:23866 [system_monitor.py:probe():229] Finished publishing system info
2024-10-03 23:26:17,867 DEBUG   HandlerThread:23866 [handler.py:handle_request():146] handle_request: python_packages
2024-10-03 23:26:22,786 DEBUG   HandlerThread:23866 [handler.py:handle_request():146] handle_request: status_report
2024-10-03 23:26:22,786 DEBUG   SenderThread:23866 [sender.py:send_request():409] send_request: status_report
2024-10-03 23:26:27,787 DEBUG   HandlerThread:23866 [handler.py:handle_request():146] handle_request: status_report
2024-10-03 23:26:27,787 DEBUG   SenderThread:23866 [sender.py:send_request():409] send_request: status_report
2024-10-03 23:26:32,788 DEBUG   HandlerThread:23866 [handler.py:handle_request():146] handle_request: status_report
2024-10-03 23:26:32,788 DEBUG   SenderThread:23866 [sender.py:send_request():409] send_request: status_report
2024-10-03 23:26:37,789 DEBUG   HandlerThread:23866 [handler.py:handle_request():146] handle_request: status_report
2024-10-03 23:26:37,789 DEBUG   SenderThread:23866 [sender.py:send_request():409] send_request: status_report
2024-10-03 23:26:42,790 DEBUG   HandlerThread:23866 [handler.py:handle_request():146] handle_request: status_report
2024-10-03 23:26:42,790 DEBUG   SenderThread:23866 [sender.py:send_request():409] send_request: status_report
2024-10-03 23:26:47,791 DEBUG   HandlerThread:23866 [handler.py:handle_request():146] handle_request: status_report
2024-10-03 23:26:47,792 DEBUG   SenderThread:23866 [sender.py:send_request():409] send_request: status_report
2024-10-03 23:26:52,792 DEBUG   HandlerThread:23866 [handler.py:handle_request():146] handle_request: status_report
2024-10-03 23:26:52,793 DEBUG   SenderThread:23866 [sender.py:send_request():409] send_request: status_report
2024-10-03 23:26:57,794 DEBUG   HandlerThread:23866 [handler.py:handle_request():146] handle_request: status_report
2024-10-03 23:26:57,794 DEBUG   SenderThread:23866 [sender.py:send_request():409] send_request: status_report
2024-10-03 23:27:02,795 DEBUG   HandlerThread:23866 [handler.py:handle_request():146] handle_request: status_report
2024-10-03 23:27:02,795 DEBUG   SenderThread:23866 [sender.py:send_request():409] send_request: status_report
2024-10-03 23:27:07,797 DEBUG   HandlerThread:23866 [handler.py:handle_request():146] handle_request: status_report
2024-10-03 23:27:07,798 DEBUG   SenderThread:23866 [sender.py:send_request():409] send_request: status_report
2024-10-03 23:27:12,799 DEBUG   HandlerThread:23866 [handler.py:handle_request():146] handle_request: status_report
2024-10-03 23:27:12,799 DEBUG   SenderThread:23866 [sender.py:send_request():409] send_request: status_report
2024-10-03 23:27:17,800 DEBUG   HandlerThread:23866 [handler.py:handle_request():146] handle_request: status_report
2024-10-03 23:27:17,800 DEBUG   SenderThread:23866 [sender.py:send_request():409] send_request: status_report
2024-10-03 23:27:17,808 DEBUG   SystemMonitor:23866 [system_monitor.py:_start():172] Starting system metrics aggregation loop
2024-10-03 23:27:22,801 DEBUG   HandlerThread:23866 [handler.py:handle_request():146] handle_request: status_report
2024-10-03 23:27:22,802 DEBUG   SenderThread:23866 [sender.py:send_request():409] send_request: status_report
2024-10-03 23:27:27,802 DEBUG   HandlerThread:23866 [handler.py:handle_request():146] handle_request: status_report
2024-10-03 23:27:27,803 DEBUG   SenderThread:23866 [sender.py:send_request():409] send_request: status_report
2024-10-03 23:27:32,803 DEBUG   HandlerThread:23866 [handler.py:handle_request():146] handle_request: status_report
2024-10-03 23:27:32,804 DEBUG   SenderThread:23866 [sender.py:send_request():409] send_request: status_report
2024-10-03 23:27:37,804 DEBUG   HandlerThread:23866 [handler.py:handle_request():146] handle_request: status_report
2024-10-03 23:27:37,805 DEBUG   SenderThread:23866 [sender.py:send_request():409] send_request: status_report
2024-10-03 23:27:38,863 WARNING StreamThr :23866 [internal.py:is_dead():414] Internal process exiting, parent pid 21655 disappeared
2024-10-03 23:27:38,863 ERROR   StreamThr :23866 [internal.py:wandb_internal():152] Internal process shutdown.
2024-10-03 23:27:39,805 INFO    HandlerThread:23866 [handler.py:finish():869] shutting down handler
2024-10-03 23:27:39,805 INFO    WriterThread:23866 [datastore.py:close():296] close: /root/paddlejob/workspace/env_run/llama3/LLaMA-Factory-main/wandb/offline-run-20241003_232617-9ajt74y3/run-9ajt74y3.wandb
2024-10-03 23:27:39,805 INFO    SenderThread:23866 [sender.py:finish():1572] shutting down sender
2024-10-03 23:27:39,806 INFO    HandlerThread:23866 [system_monitor.py:finish():203] Stopping system monitor
2024-10-03 23:27:39,807 DEBUG   SystemMonitor:23866 [system_monitor.py:_start():179] Finished system metrics aggregation loop
2024-10-03 23:27:39,808 INFO    HandlerThread:23866 [interfaces.py:finish():202] Joined cpu monitor
2024-10-03 23:27:39,808 DEBUG   SystemMonitor:23866 [system_monitor.py:_start():183] Publishing last batch of metrics
2024-10-03 23:27:39,809 INFO    HandlerThread:23866 [interfaces.py:finish():202] Joined disk monitor
2024-10-03 23:27:39,817 INFO    HandlerThread:23866 [interfaces.py:finish():202] Joined gpu monitor
2024-10-03 23:27:39,817 INFO    HandlerThread:23866 [interfaces.py:finish():202] Joined memory monitor
2024-10-03 23:27:39,818 INFO    HandlerThread:23866 [interfaces.py:finish():202] Joined network monitor
2024-10-03 23:27:41,808 INFO    MainThread:23866 [internal.py:handle_exit():76] Internal process exited
